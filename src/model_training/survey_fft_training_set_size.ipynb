{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time as time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from data_repository import DataRepository\n",
    "from model_training_ultils import ModelEvaluationUltis\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaludation_tool = ModelEvaluationUltis()\n",
    "data_repo = DataRepository(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, _, test_clean, y_test_clean = data_repo.load_fft_data(clean_data=True)\n",
    "_, _, _, _, test_unclean, y_test_unclean = data_repo.load_fft_data(clean_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_k_indices(amplitudes, k):\n",
    "    # Get the indices of the top 50 elements\n",
    "    top_k_indices = np.argsort(amplitudes)[-k:][::-1]\n",
    "    highest_ampls = amplitudes[top_k_indices]\n",
    "    return highest_ampls\n",
    "\n",
    "def get_x_by_top_ampls(k, ampls):\n",
    "    X = []\n",
    "    for ampl in ampls:\n",
    "        X.append(find_top_k_indices(amplitudes=ampl, k=k))\n",
    "    return np.array(X)\n",
    "\n",
    "X_test_clean = get_x_by_top_ampls(k=1, ampls=test_clean)\n",
    "X_test_unclean = get_x_by_top_ampls(k=1, ampls=test_unclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset clean: (2012, 1), y: (2012,)\n",
      "Test dataset unclean: (2160, 1), y(2160,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test dataset clean: {X_test_clean.shape}, y: {y_test_clean.shape}\")\n",
    "print(f\"Test dataset unclean: {X_test_unclean.shape}, y{y_test_unclean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Label encoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_test_clean = label_encoder.fit_transform(y_test_clean)\n",
    "y_test_unclean = label_encoder.transform(y_test_unclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['error', 'normal', 'overcurrent', 'overheating', 'zero']\n",
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(list(label_encoder.classes_))\n",
    "print(label_encoder.transform(list(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 445, 1: 419, 2: 454, 3: 411, 4: 431}\n",
      "{0: 414, 1: 394, 2: 421, 3: 374, 4: 409}\n"
     ]
    }
   ],
   "source": [
    "print(data_repo.count_labels(y_test_unclean))\n",
    "print(data_repo.count_labels(y_test_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_on_clean_test_set(file_name, clean_data: bool):\n",
    "    accuracy_arr = []\n",
    "    X_trains, y_trains = data_repo.read_train_fft_survey_data(file_name)\n",
    "    for i in range(X_trains.shape[0]):\n",
    "        train_ampls = X_trains[i]\n",
    "        X_train = get_x_by_top_ampls(k=1, ampls=train_ampls)\n",
    "        y_train = label_encoder.transform(y_trains[i])\n",
    "        rf_current = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=42)\n",
    "        rf_current.fit(X_train, y_train)\n",
    "        if clean_data:\n",
    "            y_pred = rf_current.predict(X_test_clean)\n",
    "            accuracy_arr.append(accuracy_score(y_pred=y_pred, y_true=y_test_clean))\n",
    "        else:\n",
    "            y_pred = rf_current.predict(X_test_unclean)\n",
    "            accuracy_arr.append(accuracy_score(y_pred=y_pred, y_true=y_test_unclean))\n",
    "    return np.array(accuracy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_time(file_name):\n",
    "    training_times = []\n",
    "    X_trains, y_trains = data_repo.read_train_fft_survey_data(file_name)\n",
    "    for i in range(X_trains.shape[0]):\n",
    "        train_ampls = X_trains[i]\n",
    "        X_train = get_x_by_top_ampls(k=1, ampls=train_ampls)\n",
    "        y_train = label_encoder.transform(y_trains[i])\n",
    "        start_time = time.time()\n",
    "        rf_current = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=42)\n",
    "        rf_current.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        training_times.append(end_time-start_time)\n",
    "    return training_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surveying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_accuracy_scores = []\n",
    "for i in [1000, 2000, 4000, 6000, 8000]:\n",
    "    file_name =f\"../../data/survery_data/clean_data/train_files_{i}.xlsx\"\n",
    "    clean_accuracy_scores.append(get_accuracy_on_clean_test_set(file_name=file_name, clean_data=True))\n",
    "clean_accuracy_scores = np.array(clean_accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_accuracy_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97415507, 0.97713718, 0.972167  , 0.97117296, 0.96322068,\n",
       "        0.96819085, 0.97415507, 0.96471173, 0.972167  , 0.97415507],\n",
       "       [0.96918489, 0.97166998, 0.97365805, 0.97365805, 0.98210736,\n",
       "        0.97614314, 0.97266402, 0.97067594, 0.97813121, 0.97117296],\n",
       "       [0.98011928, 0.97912525, 0.97813121, 0.97316103, 0.97713718,\n",
       "        0.97912525, 0.97713718, 0.97763419, 0.97465209, 0.96968191],\n",
       "       [0.98011928, 0.98161034, 0.97862823, 0.97813121, 0.97614314,\n",
       "        0.97664016, 0.97813121, 0.97415507, 0.97862823, 0.97415507],\n",
       "       [0.97713718, 0.97713718, 0.97713718, 0.97713718, 0.97763419,\n",
       "        0.97614314, 0.97465209, 0.97614314, 0.97713718, 0.97614314]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_accuracy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_training_time = []\n",
    "for i in [1000, 2000, 4000, 6000, 8000]:\n",
    "    file_name =f\"../../data/survery_data/clean_data/train_files_{i}.xlsx\"\n",
    "    clean_training_time.append(get_training_time(file_name=file_name))\n",
    "clean_training_time = np.array(clean_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_training_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07059479, 0.06880856, 0.06947517, 0.06915379, 0.06918359,\n",
       "        0.0686667 , 0.06967807, 0.07008505, 0.06868911, 0.06851149],\n",
       "       [0.09302878, 0.09278393, 0.09866023, 0.0947485 , 0.09389424,\n",
       "        0.09315228, 0.09298611, 0.0952332 , 0.09353089, 0.09247923],\n",
       "       [0.14365292, 0.14135218, 0.14731669, 0.14474058, 0.14457393,\n",
       "        0.14436889, 0.1434865 , 0.14407253, 0.14424706, 0.14095235],\n",
       "       [0.20282054, 0.2011447 , 0.20278716, 0.20369101, 0.20062327,\n",
       "        0.20018053, 0.2085762 , 0.20055556, 0.20144796, 0.20207024],\n",
       "       [0.25165272, 0.25160551, 0.25158262, 0.25111866, 0.25367427,\n",
       "        0.25029683, 0.2518971 , 0.25136495, 0.25151324, 0.25141215]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unclean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy score with unclean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_accuracy_scores = []\n",
    "for i in [1000, 2000, 4000, 6000, 8000]:\n",
    "    file_name =f\"../../data/survery_data/unclean_data/train_files_{i}.xlsx\"\n",
    "    unclean_accuracy_score = get_accuracy_on_clean_test_set(file_name=file_name, clean_data=False)\n",
    "    unclean_accuracy_scores.append(unclean_accuracy_score)\n",
    "unclean_accuracy_scores = np.array(unclean_accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_accuracy_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95555556, 0.93981481, 0.94907407, 0.96527778, 0.93935185,\n",
       "        0.95925926, 0.95324074, 0.9537037 , 0.94953704, 0.95833333],\n",
       "       [0.94907407, 0.95092593, 0.95138889, 0.9625    , 0.94814815,\n",
       "        0.95      , 0.94537037, 0.95185185, 0.95138889, 0.95324074],\n",
       "       [0.94861111, 0.95277778, 0.95509259, 0.95694444, 0.9537037 ,\n",
       "        0.9537037 , 0.95231481, 0.95972222, 0.95324074, 0.95416667],\n",
       "       [0.95416667, 0.95462963, 0.95555556, 0.95833333, 0.95462963,\n",
       "        0.95509259, 0.95231481, 0.95787037, 0.95787037, 0.95324074],\n",
       "       [0.95462963, 0.95462963, 0.95416667, 0.95416667, 0.95555556,\n",
       "        0.95555556, 0.95277778, 0.95972222, 0.95462963, 0.95694444]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_accuracy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time with unclean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_training_time = []\n",
    "for i in [1000, 2000, 4000, 6000, 8000]:\n",
    "    file_name =f\"../../data/survery_data/unclean_data/train_files_{i}.xlsx\"\n",
    "    unclean_training_time.append(get_training_time(file_name=file_name))\n",
    "unclean_training_time = np.array(unclean_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07299209, 0.07270193, 0.07272339, 0.07280636, 0.07376599,\n",
       "        0.07345295, 0.07413793, 0.07297182, 0.07276917, 0.07181978],\n",
       "       [0.09959769, 0.09990406, 0.09957647, 0.09919906, 0.10720992,\n",
       "        0.10178375, 0.09988523, 0.10051847, 0.09963799, 0.10031438],\n",
       "       [0.15742517, 0.15798044, 0.15540481, 0.15824342, 0.1584146 ,\n",
       "        0.15974069, 0.15738583, 0.15706515, 0.15868068, 0.15705276],\n",
       "       [0.2287209 , 0.22587585, 0.22205114, 0.2244556 , 0.22211814,\n",
       "        0.2240715 , 0.23219991, 0.22534084, 0.22195077, 0.23160768],\n",
       "       [0.28620005, 0.28422856, 0.2837739 , 0.27941418, 0.27993941,\n",
       "        0.28415561, 0.28335524, 0.28166652, 0.2813611 , 0.28078914]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_accuracy_scores_df = pd.DataFrame(clean_accuracy_scores)\n",
    "unclean_accuracy_scores_df = pd.DataFrame(unclean_accuracy_scores)\n",
    "clean_accuracy_scores_df.to_excel(\"../../output/survey_data/20240110_clean_rf-fft_acc_scores_training_size.xlsx\")\n",
    "unclean_accuracy_scores_df.to_excel(\"../../output/survey_data/20240110_unclean_rf-fft_acc_scores_training_size.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_training_time_df = pd.DataFrame(clean_training_time)\n",
    "unclean_training_time_df = pd.DataFrame(unclean_training_time)\n",
    "clean_training_time_df.to_excel(\"../../output/survey_data/20240110_clean_rf-fft_training_time.xlsx\")\n",
    "unclean_training_time_df.to_excel(\"../../output/survey_data/20240110_unclean_rf-fft_training_time.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
