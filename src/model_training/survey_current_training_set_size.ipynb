{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time as time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from data_repository import DataRepository\n",
    "from model_training_ultils import ModelEvaluationUltis\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaludation_tool = ModelEvaluationUltis()\n",
    "data_repo = DataRepository(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, _, X_test_clean, y_test_clean = data_repo.load_current_data(clean_data=True)\n",
    "_, _, _, _, X_test_unclean, y_test_unclean = data_repo.load_current_data(clean_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: X: (2012, 9000), y: (2012,)\n",
      "Test dataset X: (2160, 9000), y(2160,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset: X: {X_test_clean.shape}, y: {y_test_clean.shape}\")\n",
    "print(f\"Test dataset X: {X_test_unclean.shape}, y{y_test_unclean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Label encoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_test_clean = label_encoder.fit_transform(y_test_clean)\n",
    "y_test_unclean = label_encoder.transform(y_test_unclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['error', 'normal', 'overcurrent', 'overheating', 'zero']\n",
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(list(label_encoder.classes_))\n",
    "print(label_encoder.transform(list(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 445, 1: 419, 2: 454, 3: 411, 4: 431}\n",
      "{0: 414, 1: 394, 2: 421, 3: 374, 4: 409}\n"
     ]
    }
   ],
   "source": [
    "print(data_repo.count_labels(y_test_unclean))\n",
    "print(data_repo.count_labels(y_test_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_on_clean_test_set(file_name, clean_data: bool):\n",
    "    accuracy_arr = []\n",
    "    X_trains, y_trains = data_repo.read_train_current_survey_data(file_name)\n",
    "    for i in range(X_trains.shape[0]):\n",
    "        X_train = X_trains[i]\n",
    "        y_train = label_encoder.transform(y_trains[i])\n",
    "        rf_current = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=42)\n",
    "        rf_current.fit(X_train, y_train)\n",
    "        if clean_data:\n",
    "            y_pred = rf_current.predict(X_test_clean)\n",
    "            accuracy_arr.append(accuracy_score(y_pred=y_pred, y_true=y_test_clean))\n",
    "        else:\n",
    "            y_pred = rf_current.predict(X_test_unclean)\n",
    "            accuracy_arr.append(accuracy_score(y_pred=y_pred, y_true=y_test_unclean))\n",
    "    return np.array(accuracy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_time(file_name):\n",
    "    training_times = []\n",
    "    X_trains, y_trains = data_repo.read_train_current_survey_data(file_name)\n",
    "    for i in range(X_trains.shape[0]):\n",
    "        X_train = X_trains[i]\n",
    "        y_train = label_encoder.transform(y_trains[i])\n",
    "        start_time = time.time()\n",
    "        rf_current = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=42)\n",
    "        rf_current.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        training_times.append(end_time-start_time)\n",
    "    return np.array(training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surveying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Accuracy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "for i in [1000, 2000, 4000, 6000, 8000]:\n",
    "    file_name =f\"../../data/survery_data/clean_data/train_files_{i}.xlsx\"\n",
    "    accuracy_scores.append(get_accuracy_on_clean_test_set(file_name=file_name, clean_data=True))\n",
    "accuracy_scores = np.array(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94980119, 0.94930417, 0.95526839, 0.95328032, 0.95477137,\n",
       "        0.95477137, 0.95178926, 0.94880716, 0.95079523, 0.95079523],\n",
       "       [0.96371769, 0.95725646, 0.96222664, 0.9666998 , 0.95775348,\n",
       "        0.96719682, 0.95576541, 0.95079523, 0.96371769, 0.97017893],\n",
       "       [0.97564612, 0.97564612, 0.97862823, 0.97465209, 0.97813121,\n",
       "        0.972167  , 0.97813121, 0.97564612, 0.98011928, 0.97614314],\n",
       "       [0.98011928, 0.97962227, 0.97912525, 0.9806163 , 0.98111332,\n",
       "        0.97813121, 0.97813121, 0.97664016, 0.97912525, 0.97912525],\n",
       "       [0.97912525, 0.98111332, 0.9806163 , 0.97912525, 0.98210736,\n",
       "        0.98111332, 0.98111332, 0.97912525, 0.9806163 , 0.98111332]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_accuracy_scores = pd.DataFrame(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_accuracy_scores.to_excel(\"../../output/survey_data/20240109_clean_acc_scores.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training time__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_training_time = []\n",
    "for i in [1000, 2000, 4000, 6000, 8000]:\n",
    "    file_name =f\"../../data/survery_data/clean_data/train_files_{i}.xlsx\"\n",
    "    clean_training_time.append(get_training_time(file_name=file_name))\n",
    "clean_training_time = np.array(clean_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "[[0.47248745 0.47308135 0.4732492  0.48269606 0.46145749 0.45695114\n",
      "  0.48279285 0.49483848 0.47021914 0.46414495]\n",
      " [0.92775583 0.93511176 0.93307734 0.95550537 0.92694712 0.90880775\n",
      "  0.9388721  0.95024228 0.93568444 0.90597796]\n",
      " [1.98778987 1.9055841  2.02529216 2.08870959 2.01255226 1.93543696\n",
      "  2.04200602 1.95783734 1.95797181 2.04196739]\n",
      " [3.12076378 2.98412442 3.08451939 3.09969521 3.05897212 3.0110755\n",
      "  3.08352852 3.11764765 3.02921414 3.02827287]\n",
      " [3.97341871 3.98595738 3.99378157 3.96893668 3.9870739  4.01407743\n",
      "  3.99215794 3.94830537 3.98925567 3.97640133]]\n"
     ]
    }
   ],
   "source": [
    "print(clean_training_time.shape)\n",
    "print(clean_training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unclean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training time__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_accuracy_scores = []\n",
    "for i in [1000, 2000, 4000, 6000, 8000]:\n",
    "    file_name =f\"../../data/survery_data/unclean_data/train_files_{i}.xlsx\"\n",
    "    unclean_accuracy_score = get_accuracy_on_clean_test_set(file_name=file_name, clean_data=False)\n",
    "    unclean_accuracy_scores.append(unclean_accuracy_score)\n",
    "unclean_accuracy_scores = np.array(unclean_accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92361111, 0.91944444, 0.90740741, 0.90787037, 0.9287037 ,\n",
       "        0.92731481, 0.91990741, 0.93518519, 0.925     , 0.925     ],\n",
       "       [0.92453704, 0.93148148, 0.93842593, 0.9375    , 0.94583333,\n",
       "        0.94259259, 0.9287037 , 0.93703704, 0.94074074, 0.93657407],\n",
       "       [0.94953704, 0.95046296, 0.94953704, 0.95694444, 0.95324074,\n",
       "        0.95509259, 0.95231481, 0.95694444, 0.94814815, 0.94814815],\n",
       "       [0.95462963, 0.95833333, 0.95648148, 0.95694444, 0.95694444,\n",
       "        0.95740741, 0.95648148, 0.95740741, 0.95694444, 0.95694444],\n",
       "       [0.95462963, 0.95694444, 0.95787037, 0.95555556, 0.95416667,\n",
       "        0.95555556, 0.95601852, 0.95092593, 0.95416667, 0.95787037]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_accuracy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_accuracy_scores_df = pd.DataFrame(unclean_accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_accuracy_scores_df.to_excel(\"../../output/survey_data/20240109_unclean_acc_scores_training_size.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training time__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_training_time = []\n",
    "for i in [1000, 2000, 4000, 6000, 8000]:\n",
    "    file_name =f\"../../data/survery_data/unclean_data/train_files_{i}.xlsx\"\n",
    "    unclean_training_time.append(get_training_time(file_name=file_name))\n",
    "unclean_training_time = np.array(unclean_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "[[0.51997209 0.53142667 0.53553104 0.52388406 0.56661606 0.54328966\n",
      "  0.56497312 0.55669856 0.54467845 0.53489161]\n",
      " [1.10153937 1.11818528 1.12229133 1.12344813 1.12854171 1.11650658\n",
      "  1.13870645 1.15917945 1.09220195 1.09401155]\n",
      " [2.33148503 2.34348941 2.32309508 2.38808846 2.48055363 2.47954369\n",
      "  2.45864868 2.44991946 2.40015841 2.39717841]\n",
      " [3.84642339 3.8426621  3.93744087 3.85481572 3.85821509 3.9126966\n",
      "  3.85255623 3.84200716 3.73213696 3.85249162]\n",
      " [4.97727299 4.99130344 4.99779224 4.99063516 5.0135107  4.95985079\n",
      "  4.98642468 4.97688437 4.98004341 4.98881745]]\n"
     ]
    }
   ],
   "source": [
    "print(unclean_training_time.shape)\n",
    "print(unclean_training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_training_time_df = pd.DataFrame(clean_training_time)\n",
    "unclean_training_time_df = pd.DataFrame(unclean_training_time)\n",
    "clean_training_time_df.to_excel(\"../../output/survey_data/20240110_clean_rf-current_training_time.xlsx\")\n",
    "unclean_training_time_df.to_excel(\"../../output/survey_data/20240110_unclean_rf-current_training_time.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
