{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.fftpack import fft, ifft\n",
    "from data_repository import DataRepository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chuẩn bị dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_repo = DataRepository(\"../.env\")\n",
    "#Clean data\n",
    "X_Train, y_train, X_validation, y_validation, X_test, y_test = data_repo.load_current_data(clean_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files, validation_files, test_files = data_repo.load_unclean_file_names()\n",
    "file_names = np.concatenate([train_files, validation_files, test_files])\n",
    "file_names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([X_Train, X_validation, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 9000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "def equalize_column_lengths(data_dict):\n",
    "    # Find the maximum length among all columns\n",
    "    max_length = max(len(data) for data in data_dict.values())\n",
    "    \n",
    "    # Check and fill columns to ensure equality of lengths\n",
    "    for key, value in data_dict.items():\n",
    "        current_length = len(value)\n",
    "        if current_length < max_length:\n",
    "            # Determine the fill value based on data type\n",
    "            fill_value = 0 if isinstance(value[0], (int, float)) else np.nan\n",
    "            \n",
    "            # Pad the array to match the maximum length\n",
    "            data_dict[key] = np.pad(value, (0, max_length - current_length), 'constant', constant_values=fill_value)\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def my_cal_fft(signal, sample_rate):\n",
    "    pnts   = len(signal) # number of time points\n",
    "    # prepare the Fourier transform\n",
    "    fourTime = np.array(range(pnts))/pnts #Normalize time vector!\n",
    "    fCoefs   = np.zeros((pnts,),dtype=complex) #Init output vector of the fourier coefficient\n",
    "    for k in range(pnts):\n",
    "        # create complex sine wave\n",
    "        csw = np.exp( -1j*2*np.pi*k*fourTime )\n",
    "        # compute dot product between sine wave and signal \n",
    "        # these are called the Fourier coefficients\n",
    "        # using vectorization for fast calculation\n",
    "        # Normalize the Fourier coefficient by divine it to 1/N -> reduce the computational cost.\n",
    "        fCoefs[k] = np.sum( np.multiply(signal,csw) ) / pnts\n",
    "    # extract amplitudes only in the first half\n",
    "    hz = np.linspace(0,sample_rate/2,int(math.floor(pnts/2.)+1))\n",
    "    ampls = 2*np.abs(fCoefs)[0:len(hz)]\n",
    "    # compute frequencies vector\n",
    "    return ampls, hz\n",
    "\n",
    "def cal_and_store_fft(signal, file_name):\n",
    "    file_path = f\"../../data/original_fft_data/{file_name}\"\n",
    "    if os.path.exists(file_path):\n",
    "        # File already exists, skip the iteration\n",
    "        return False\n",
    "    ampls, hz = my_cal_fft(signal=signal, sample_rate=1000)\n",
    "    # Determine the maximum length among signal, ampls, and hz\n",
    "    data_dict = { \n",
    "        \"Amplitude\": ampls,\n",
    "        \"Frequency\": hz\n",
    "    }\n",
    "    data_dict = equalize_column_lengths(data_dict=data_dict)\n",
    "    df = pd.DataFrame(data=data_dict)\n",
    "    df.to_csv(file_path, index=False)\n",
    "    return True\n",
    "\n",
    "# Single proccess\n",
    "# for i in tqdm(range(0, len(data), 1), desc=\"Processing signals\"):\n",
    "#     cal_and_store_fft(signal=data[i], file_name=file_names[i])\n",
    "\n",
    "# Function to be parallelized\n",
    "def process_data(args):\n",
    "    signal, file_name = args\n",
    "    cal_and_store_fft(signal, file_name)\n",
    "    \n",
    "def plot_frequency_domain(ampls, hz):\n",
    "    srate  = 1000 # hz\n",
    "    dc_ampl = ampls[0]\n",
    "    print(f\"Dc element: {dc_ampl}\")\n",
    "    #Don't plot DC element since it's too big\n",
    "    ampls = ampls[1:len(ampls)]\n",
    "    hz = hz[1:len(hz)]\n",
    "    plt.subplot(212)  # 2 rows, 1 column, 2nd subplot\n",
    "    plt.stem(hz,ampls[range(len(hz))])\n",
    "    plt.xlabel('Frequency (Hz)'), plt.ylabel('Amplitude (a.u.)')\n",
    "    plt.xlim(0, srate//2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = X_Train[1]\n",
    "ampls, hz = my_cal_fft(signal=signal, sample_rate=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4501,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = { \n",
    "    \"Amplitude\": ampls,\n",
    "    \"Frequency\": hz\n",
    "}\n",
    "data_dict = equalize_column_lengths(data_dict=data_dict)\n",
    "df = pd.DataFrame(data=data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing signals: 100%|██████████| 12000/12000 [56:06<00:00,  3.56it/s] \n"
     ]
    }
   ],
   "source": [
    "# Use ProcessPoolExecutor for parallel processing\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    args_list = zip(data, file_names)\n",
    "    results = list(tqdm(executor.map(process_data, args_list), total=len(data), desc=\"Processing signals\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12000 files in the directory ../../data/original_fft_data/.\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"../../data/original_fft_data/\"  # Replace this with the path to your directory\n",
    "\n",
    "# Get the list of files in the directory\n",
    "files = os.listdir(directory_path)\n",
    "\n",
    "# Count the number of files\n",
    "num_files = len(files)\n",
    "\n",
    "print(f\"There are {num_files} files in the directory {directory_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
